{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "from dotenv import load_dotenv\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface and WandB authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"C:/Users/User/Data Science/Deep Learning/Generative AI/Fine Tuning LLMs/fine-tuning llama 3.2 1B/research.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0551969e89fa4b85b33759cd9c04c529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Data Science\\Deep Learning\\Generative AI\\Fine Tuning LLMs\\fine-tuning llama 3.2 1B\\wandb\\run-20241004_204804-7pibddmb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb' target=\"_blank\">youthful-surf-4</a></strong> to <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb' target=\"_blank\">https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.2 on Customer Support Dataset',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "new_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\n",
    "dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data type and attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLoRA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\utils\\modeling.py:856: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  _ = torch.tensor([0], device=i)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIrst, we will train with only 1000 samples of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.shuffle(seed=65).select(range(1000, 1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['instruction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing to match our chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "    Be polite to customers and answer all their questions.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_template(row):\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model, trust_remote_code=True)\n",
    "\n",
    "    instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "        Be polite to customers and answer all their questions.\n",
    "        \"\"\"\n",
    "\n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n",
    "\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6ea48d65c94924b39e08c4b8f05a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(format_chat_template, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf17436d940e45a1bd368c1de52d0259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(format_chat_template, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f023342963248ba96c049389f99e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eb9cddd3094ffdb7ec9e8f9307c70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Victorano/customer-support-1k/commit/157c1da2fb0e842461161ea69d8551fc26715b4d', commit_message='Upload dataset', commit_description='', oid='157c1da2fb0e842461161ea69d8551fc26715b4d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"customer-support-1k\", token=HF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39fcb305d2545249bf6e44a456db776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdc9c5463f0482286968261d7a597c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Victorano/customer-support-test-200/commit/af6cd0525f81ae93586b3035fb3e5adb819a651b', commit_message='Upload dataset', commit_description='', oid='af6cd0525f81ae93586b3035fb3e5adb819a651b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.push_to_hub(\"customer-support-test-200\", token=HF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nwhere do i enter a different shipping address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAh, I understand that you\\'re looking to enter a different shipping address. Allow me to guide you through the process:\\n\\n1. Log in to your account on our website.\\n2. Navigate to the \"My Account\" or \"Profile\" section, which can usually be found in the top right corner of the page.\\n3. Look for the \"Shipping Addresses\" or similar option. It may also be labeled as \"Manage Addresses\" or \"Delivery Information.\"\\n4. Click on that option to access your saved addresses.\\n5. To enter a different shipping address, you\\'ll most likely have the choice to either \"Edit\" an existing address or \"Add a New Address.\"\\n6. If you choose to edit, find the address you want to update and click on the \"Edit\" or \"Modify\" button. Make your changes and then save.\\n7. If you want to add a completely new address, click on the \"Add a New Address\" or a similar option. Fill in the necessary details and save.\\n\\nRemember to double-check all the information you enter to ensure the accuracy of your shipping address. If you encounter any issues or have further questions, please don\\'t hesitate to ask. We\\'re here to support you every step of the way!<|eot_id|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the saved datasets from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Victorano/customer-support-1k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nchange to {{Account Type}} acount<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThank you for expressing interest in upgrading to the {{Account Type}} account! I\\'d be delighted to guide you through the process:\\n\\n1. Access Your Account: Start by logging in to our platform using your credentials.\\n2. Go to Account Settings: Once you\\'re logged in, navigate to the \"Account Settings\" section.\\n3. Upgrade Option: Look for the option that allows you to upgrade your account type.\\n4. Select {{Account Type}} Account: Choose the \"{{Account Type}} Account\" option from the available choices.\\n5. Follow the Prompts: Follow the prompts on the screen to complete the upgrade process successfully.\\n\\nShould you encounter any difficulties during the upgrade or have any additional questions, please don\\'t hesitate to reach out. We value your decision to upgrade to the {{Account Type}} account and will ensure a seamless transition. Enjoy the exclusive benefits that come with the {{Account Type}} account!<|eot_id|>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"Victorano/customer-support-test-200\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nis it possible to buy several items<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThank you for your interest in purchasing several items from us! We have a wide range of products available for you to choose from. To place your order, simply browse through our online catalog and add the items you want to your shopping cart. Once you've selected all the items you wish to purchase, proceed to the checkout page and follow the prompts to complete your order. If you have any questions or need assistance during the process, feel free to reach out to our customer service team who will be more than happy to help. Happy shopping!<|eot_id|>\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Model\n",
    "extract the linear model name from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down_proj', 'o_proj', 'up_proj', 'q_proj', 'v_proj', 'gate_proj', 'k_proj']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Linear Module name to create the LoRA Adapter, this is only what we will be fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fac18f7834d3e93cc4e746f925bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53d7eabd3af45a3b55e291ab4d1deb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0753, 'grad_norm': 2.98009991645813, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 2.196, 'grad_norm': 3.350388288497925, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 2.4107, 'grad_norm': 3.648029088973999, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.463, 'grad_norm': 3.2274019718170166, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3088, 'grad_norm': 2.405561923980713, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
      "{'loss': 2.1519, 'grad_norm': 2.094228506088257, 'learning_rate': 0.00012, 'epoch': 0.01}\n",
      "{'loss': 1.892, 'grad_norm': 1.8950233459472656, 'learning_rate': 0.00014, 'epoch': 0.01}\n",
      "{'loss': 1.9028, 'grad_norm': 1.8293263912200928, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 1.7341, 'grad_norm': 1.8322831392288208, 'learning_rate': 0.00018, 'epoch': 0.02}\n",
      "{'loss': 1.7392, 'grad_norm': 1.7804890871047974, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 1.3917, 'grad_norm': 1.875309944152832, 'learning_rate': 0.0001995918367346939, 'epoch': 0.02}\n",
      "{'loss': 1.4825, 'grad_norm': 2.3352768421173096, 'learning_rate': 0.00019918367346938775, 'epoch': 0.02}\n",
      "{'loss': 1.168, 'grad_norm': 1.8246804475784302, 'learning_rate': 0.00019877551020408164, 'epoch': 0.03}\n",
      "{'loss': 1.1522, 'grad_norm': 1.572745442390442, 'learning_rate': 0.00019836734693877553, 'epoch': 0.03}\n",
      "{'loss': 1.1686, 'grad_norm': 1.8667722940444946, 'learning_rate': 0.00019795918367346938, 'epoch': 0.03}\n",
      "{'loss': 1.2064, 'grad_norm': 1.9192206859588623, 'learning_rate': 0.00019755102040816327, 'epoch': 0.03}\n",
      "{'loss': 1.1204, 'grad_norm': 1.9289989471435547, 'learning_rate': 0.00019714285714285716, 'epoch': 0.03}\n",
      "{'loss': 0.9123, 'grad_norm': 1.6255617141723633, 'learning_rate': 0.00019673469387755104, 'epoch': 0.04}\n",
      "{'loss': 1.0138, 'grad_norm': 1.8015104532241821, 'learning_rate': 0.0001963265306122449, 'epoch': 0.04}\n",
      "{'loss': 1.134, 'grad_norm': 1.5938031673431396, 'learning_rate': 0.0001959183673469388, 'epoch': 0.04}\n",
      "{'loss': 1.1381, 'grad_norm': 1.770037055015564, 'learning_rate': 0.00019551020408163265, 'epoch': 0.04}\n",
      "{'loss': 1.2292, 'grad_norm': 1.8855708837509155, 'learning_rate': 0.00019510204081632656, 'epoch': 0.04}\n",
      "{'loss': 1.0034, 'grad_norm': 2.319880247116089, 'learning_rate': 0.00019469387755102042, 'epoch': 0.05}\n",
      "{'loss': 1.1881, 'grad_norm': 40.26081466674805, 'learning_rate': 0.0001942857142857143, 'epoch': 0.05}\n",
      "{'loss': 1.172, 'grad_norm': 5.82710075378418, 'learning_rate': 0.00019387755102040816, 'epoch': 0.05}\n",
      "{'loss': 1.0273, 'grad_norm': 2.1957602500915527, 'learning_rate': 0.00019346938775510205, 'epoch': 0.05}\n",
      "{'loss': 1.2775, 'grad_norm': 1.6895976066589355, 'learning_rate': 0.00019306122448979593, 'epoch': 0.05}\n",
      "{'loss': 1.2091, 'grad_norm': 1.6199172735214233, 'learning_rate': 0.0001926530612244898, 'epoch': 0.06}\n",
      "{'loss': 1.256, 'grad_norm': 1.678134560585022, 'learning_rate': 0.00019224489795918368, 'epoch': 0.06}\n",
      "{'loss': 0.9384, 'grad_norm': 1.6749181747436523, 'learning_rate': 0.00019183673469387756, 'epoch': 0.06}\n",
      "{'loss': 1.0361, 'grad_norm': 1.7314282655715942, 'learning_rate': 0.00019142857142857145, 'epoch': 0.06}\n",
      "{'loss': 1.4987, 'grad_norm': 1.9965317249298096, 'learning_rate': 0.0001910204081632653, 'epoch': 0.06}\n",
      "{'loss': 1.0028, 'grad_norm': 1.520471453666687, 'learning_rate': 0.0001906122448979592, 'epoch': 0.07}\n",
      "{'loss': 1.1735, 'grad_norm': 1.467056155204773, 'learning_rate': 0.00019020408163265305, 'epoch': 0.07}\n",
      "{'loss': 1.1097, 'grad_norm': 1.7979893684387207, 'learning_rate': 0.00018979591836734697, 'epoch': 0.07}\n",
      "{'loss': 0.9674, 'grad_norm': 1.318442463874817, 'learning_rate': 0.00018938775510204083, 'epoch': 0.07}\n",
      "{'loss': 0.9892, 'grad_norm': 1.5235209465026855, 'learning_rate': 0.0001889795918367347, 'epoch': 0.07}\n",
      "{'loss': 1.0829, 'grad_norm': 1.550398826599121, 'learning_rate': 0.00018857142857142857, 'epoch': 0.08}\n",
      "{'loss': 1.0074, 'grad_norm': 1.50758957862854, 'learning_rate': 0.00018816326530612246, 'epoch': 0.08}\n",
      "{'loss': 0.9452, 'grad_norm': 1.353467345237732, 'learning_rate': 0.00018775510204081634, 'epoch': 0.08}\n",
      "{'loss': 1.0122, 'grad_norm': 1.50874662399292, 'learning_rate': 0.00018734693877551023, 'epoch': 0.08}\n",
      "{'loss': 1.0776, 'grad_norm': 1.5516750812530518, 'learning_rate': 0.0001869387755102041, 'epoch': 0.08}\n",
      "{'loss': 1.0481, 'grad_norm': 1.6335216760635376, 'learning_rate': 0.00018653061224489797, 'epoch': 0.09}\n",
      "{'loss': 1.0146, 'grad_norm': 1.853318452835083, 'learning_rate': 0.00018612244897959183, 'epoch': 0.09}\n",
      "{'loss': 0.8578, 'grad_norm': 1.7626745700836182, 'learning_rate': 0.00018571428571428572, 'epoch': 0.09}\n",
      "{'loss': 1.1167, 'grad_norm': 1.7970020771026611, 'learning_rate': 0.0001853061224489796, 'epoch': 0.09}\n",
      "{'loss': 0.9386, 'grad_norm': 1.680127739906311, 'learning_rate': 0.00018489795918367346, 'epoch': 0.09}\n",
      "{'loss': 1.1141, 'grad_norm': 1.962034821510315, 'learning_rate': 0.00018448979591836735, 'epoch': 0.1}\n",
      "{'loss': 1.0754, 'grad_norm': 2.1415789127349854, 'learning_rate': 0.00018408163265306123, 'epoch': 0.1}\n",
      "{'loss': 1.0658, 'grad_norm': 1.8593695163726807, 'learning_rate': 0.00018367346938775512, 'epoch': 0.1}\n",
      "{'loss': 1.2261, 'grad_norm': 1.302927017211914, 'learning_rate': 0.00018326530612244898, 'epoch': 0.1}\n",
      "{'loss': 1.23, 'grad_norm': 1.2338837385177612, 'learning_rate': 0.00018285714285714286, 'epoch': 0.1}\n",
      "{'loss': 1.0383, 'grad_norm': 1.2643780708312988, 'learning_rate': 0.00018244897959183672, 'epoch': 0.11}\n",
      "{'loss': 1.1042, 'grad_norm': 1.317956566810608, 'learning_rate': 0.00018204081632653064, 'epoch': 0.11}\n",
      "{'loss': 1.0979, 'grad_norm': 1.3973417282104492, 'learning_rate': 0.0001816326530612245, 'epoch': 0.11}\n",
      "{'loss': 1.204, 'grad_norm': 1.472413420677185, 'learning_rate': 0.00018122448979591838, 'epoch': 0.11}\n",
      "{'loss': 1.2954, 'grad_norm': 1.3131741285324097, 'learning_rate': 0.00018081632653061224, 'epoch': 0.11}\n",
      "{'loss': 0.9117, 'grad_norm': 1.150615930557251, 'learning_rate': 0.00018040816326530615, 'epoch': 0.12}\n",
      "{'loss': 0.916, 'grad_norm': 1.2739616632461548, 'learning_rate': 0.00018, 'epoch': 0.12}\n",
      "{'loss': 1.066, 'grad_norm': 1.4361677169799805, 'learning_rate': 0.0001795918367346939, 'epoch': 0.12}\n",
      "{'loss': 1.0591, 'grad_norm': 1.3993977308273315, 'learning_rate': 0.00017918367346938776, 'epoch': 0.12}\n",
      "{'loss': 0.9612, 'grad_norm': 1.483891248703003, 'learning_rate': 0.00017877551020408164, 'epoch': 0.12}\n",
      "{'loss': 0.849, 'grad_norm': 1.828078031539917, 'learning_rate': 0.00017836734693877553, 'epoch': 0.13}\n",
      "{'loss': 0.8789, 'grad_norm': 1.9531255960464478, 'learning_rate': 0.0001779591836734694, 'epoch': 0.13}\n",
      "{'loss': 0.8906, 'grad_norm': 2.318100929260254, 'learning_rate': 0.00017755102040816327, 'epoch': 0.13}\n",
      "{'loss': 0.8694, 'grad_norm': 2.608834743499756, 'learning_rate': 0.00017714285714285713, 'epoch': 0.13}\n",
      "{'loss': 0.9093, 'grad_norm': 1.5531765222549438, 'learning_rate': 0.00017673469387755104, 'epoch': 0.13}\n",
      "{'loss': 0.8794, 'grad_norm': 1.7597436904907227, 'learning_rate': 0.0001763265306122449, 'epoch': 0.14}\n",
      "{'loss': 0.9034, 'grad_norm': 1.482979655265808, 'learning_rate': 0.0001759183673469388, 'epoch': 0.14}\n",
      "{'loss': 0.9829, 'grad_norm': 1.588975191116333, 'learning_rate': 0.00017551020408163265, 'epoch': 0.14}\n",
      "{'loss': 0.9665, 'grad_norm': 1.6832164525985718, 'learning_rate': 0.00017510204081632653, 'epoch': 0.14}\n",
      "{'loss': 0.8486, 'grad_norm': 1.5053411722183228, 'learning_rate': 0.00017469387755102042, 'epoch': 0.14}\n",
      "{'loss': 0.7064, 'grad_norm': 1.5501614809036255, 'learning_rate': 0.0001742857142857143, 'epoch': 0.15}\n",
      "{'loss': 0.8976, 'grad_norm': 1.9202347993850708, 'learning_rate': 0.00017387755102040816, 'epoch': 0.15}\n",
      "{'loss': 0.9247, 'grad_norm': 1.9476807117462158, 'learning_rate': 0.00017346938775510205, 'epoch': 0.15}\n",
      "{'loss': 0.9783, 'grad_norm': 2.014578342437744, 'learning_rate': 0.00017306122448979594, 'epoch': 0.15}\n",
      "{'loss': 0.9124, 'grad_norm': 1.974927544593811, 'learning_rate': 0.00017265306122448982, 'epoch': 0.15}\n",
      "{'loss': 0.9214, 'grad_norm': 2.1460046768188477, 'learning_rate': 0.00017224489795918368, 'epoch': 0.16}\n",
      "{'loss': 0.8346, 'grad_norm': 1.4190789461135864, 'learning_rate': 0.00017183673469387757, 'epoch': 0.16}\n",
      "{'loss': 1.0903, 'grad_norm': 2.064964771270752, 'learning_rate': 0.00017142857142857143, 'epoch': 0.16}\n",
      "{'loss': 1.0201, 'grad_norm': 1.8383897542953491, 'learning_rate': 0.0001710204081632653, 'epoch': 0.16}\n",
      "{'loss': 0.9335, 'grad_norm': 1.8856247663497925, 'learning_rate': 0.0001706122448979592, 'epoch': 0.16}\n",
      "{'loss': 0.6548, 'grad_norm': 1.794032335281372, 'learning_rate': 0.00017020408163265306, 'epoch': 0.17}\n",
      "{'loss': 0.8409, 'grad_norm': 1.6264517307281494, 'learning_rate': 0.00016979591836734694, 'epoch': 0.17}\n",
      "{'loss': 0.7521, 'grad_norm': 1.6090474128723145, 'learning_rate': 0.00016938775510204083, 'epoch': 0.17}\n",
      "{'loss': 0.644, 'grad_norm': 1.6054695844650269, 'learning_rate': 0.0001689795918367347, 'epoch': 0.17}\n",
      "{'loss': 0.6979, 'grad_norm': 1.4935319423675537, 'learning_rate': 0.00016857142857142857, 'epoch': 0.17}\n",
      "{'loss': 1.161, 'grad_norm': 2.0854358673095703, 'learning_rate': 0.00016816326530612246, 'epoch': 0.18}\n",
      "{'loss': 0.713, 'grad_norm': 1.5618456602096558, 'learning_rate': 0.00016775510204081632, 'epoch': 0.18}\n",
      "{'loss': 0.8283, 'grad_norm': 1.787673830986023, 'learning_rate': 0.00016734693877551023, 'epoch': 0.18}\n",
      "{'loss': 0.856, 'grad_norm': 1.8017436265945435, 'learning_rate': 0.0001669387755102041, 'epoch': 0.18}\n",
      "{'loss': 0.8232, 'grad_norm': 1.6385554075241089, 'learning_rate': 0.00016653061224489797, 'epoch': 0.18}\n",
      "{'loss': 0.9122, 'grad_norm': 1.7985939979553223, 'learning_rate': 0.00016612244897959183, 'epoch': 0.19}\n",
      "{'loss': 0.9323, 'grad_norm': 1.7855110168457031, 'learning_rate': 0.00016571428571428575, 'epoch': 0.19}\n",
      "{'loss': 0.6135, 'grad_norm': 1.637880802154541, 'learning_rate': 0.0001653061224489796, 'epoch': 0.19}\n",
      "{'loss': 0.7096, 'grad_norm': 1.767953872680664, 'learning_rate': 0.0001648979591836735, 'epoch': 0.19}\n",
      "{'loss': 0.6906, 'grad_norm': 1.4105433225631714, 'learning_rate': 0.00016448979591836735, 'epoch': 0.19}\n",
      "{'loss': 0.5894, 'grad_norm': 1.6194623708724976, 'learning_rate': 0.00016408163265306124, 'epoch': 0.2}\n",
      "{'loss': 0.6666, 'grad_norm': 1.7504736185073853, 'learning_rate': 0.00016367346938775512, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7397, 'grad_norm': 1.674275517463684, 'learning_rate': 0.00016326530612244898, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c77a98fd5624d369b1d1909da43178d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
