{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "\n",
    "from accelerate import infer_auto_device_map, init_empty_weights\n",
    "\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "from dotenv import load_dotenv\n",
    "import bitsandbytes as bnb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface and WandB authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"C:/Users/User/Data Science/Deep Learning/Generative AI/Fine Tuning LLMs/fine-tuning llama 3.2 1B/research.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0551969e89fa4b85b33759cd9c04c529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Data Science\\Deep Learning\\Generative AI\\Fine Tuning LLMs\\fine-tuning llama 3.2 1B\\wandb\\run-20241004_204804-7pibddmb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb' target=\"_blank\">youthful-surf-4</a></strong> to <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb' target=\"_blank\">https://wandb.ai/victordareai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/7pibddmb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.2 on Customer Support Dataset',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "new_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\n",
    "dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data type and attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLoRA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\utils\\modeling.py:856: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  _ = torch.tensor([0], device=i)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIrst, we will train with only 1000 samples of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(seed=65).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.shuffle(seed=65).select(range(1000, 1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['instruction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing to match our chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "    Be polite to customers and answer all their questions.\n",
    "    If the question is out of context and is not related to an e-commerce business, let them know you can not help and that they should look elsewhere for answers.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_template(row):\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model, trust_remote_code=True)\n",
    "\n",
    "    instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "        Be polite to customers and answer all their questions.\n",
    "        If the question is out of context and is not related to an e-commerce business, let them know you can not help and that they should look elsewhere for answers.\n",
    "        \"\"\"\n",
    "\n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n",
    "\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6ea48d65c94924b39e08c4b8f05a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(format_chat_template, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf17436d940e45a1bd368c1de52d0259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(format_chat_template, num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f023342963248ba96c049389f99e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eb9cddd3094ffdb7ec9e8f9307c70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Victorano/customer-support-1k/commit/157c1da2fb0e842461161ea69d8551fc26715b4d', commit_message='Upload dataset', commit_description='', oid='157c1da2fb0e842461161ea69d8551fc26715b4d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"customer-support-1k\", token=HF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39fcb305d2545249bf6e44a456db776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdc9c5463f0482286968261d7a597c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Victorano/customer-support-test-200/commit/af6cd0525f81ae93586b3035fb3e5adb819a651b', commit_message='Upload dataset', commit_description='', oid='af6cd0525f81ae93586b3035fb3e5adb819a651b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.push_to_hub(\"customer-support-test-200\", token=HF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nwhere do i enter a different shipping address<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAh, I understand that you\\'re looking to enter a different shipping address. Allow me to guide you through the process:\\n\\n1. Log in to your account on our website.\\n2. Navigate to the \"My Account\" or \"Profile\" section, which can usually be found in the top right corner of the page.\\n3. Look for the \"Shipping Addresses\" or similar option. It may also be labeled as \"Manage Addresses\" or \"Delivery Information.\"\\n4. Click on that option to access your saved addresses.\\n5. To enter a different shipping address, you\\'ll most likely have the choice to either \"Edit\" an existing address or \"Add a New Address.\"\\n6. If you choose to edit, find the address you want to update and click on the \"Edit\" or \"Modify\" button. Make your changes and then save.\\n7. If you want to add a completely new address, click on the \"Add a New Address\" or a similar option. Fill in the necessary details and save.\\n\\nRemember to double-check all the information you enter to ensure the accuracy of your shipping address. If you encounter any issues or have further questions, please don\\'t hesitate to ask. We\\'re here to support you every step of the way!<|eot_id|>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the saved datasets from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Victorano/customer-support-1k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nchange to {{Account Type}} acount<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThank you for expressing interest in upgrading to the {{Account Type}} account! I\\'d be delighted to guide you through the process:\\n\\n1. Access Your Account: Start by logging in to our platform using your credentials.\\n2. Go to Account Settings: Once you\\'re logged in, navigate to the \"Account Settings\" section.\\n3. Upgrade Option: Look for the option that allows you to upgrade your account type.\\n4. Select {{Account Type}} Account: Choose the \"{{Account Type}} Account\" option from the available choices.\\n5. Follow the Prompts: Follow the prompts on the screen to complete the upgrade process successfully.\\n\\nShould you encounter any difficulties during the upgrade or have any additional questions, please don\\'t hesitate to reach out. We value your decision to upgrade to the {{Account Type}} account and will ensure a seamless transition. Enjoy the exclusive benefits that come with the {{Account Type}} account!<|eot_id|>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"Victorano/customer-support-test-200\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nis it possible to buy several items<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThank you for your interest in purchasing several items from us! We have a wide range of products available for you to choose from. To place your order, simply browse through our online catalog and add the items you want to your shopping cart. Once you've selected all the items you wish to purchase, proceed to the checkout page and follow the prompts to complete your order. If you have any questions or need assistance during the process, feel free to reach out to our customer service team who will be more than happy to help. Happy shopping!<|eot_id|>\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Model\n",
    "extract the linear model name from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down_proj', 'o_proj', 'up_proj', 'q_proj', 'v_proj', 'gate_proj', 'k_proj']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Linear Module name to create the LoRA Adapter, this is only what we will be fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272fac18f7834d3e93cc4e746f925bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53d7eabd3af45a3b55e291ab4d1deb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0753, 'grad_norm': 2.98009991645813, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 2.196, 'grad_norm': 3.350388288497925, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 2.4107, 'grad_norm': 3.648029088973999, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.463, 'grad_norm': 3.2274019718170166, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3088, 'grad_norm': 2.405561923980713, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
      "{'loss': 2.1519, 'grad_norm': 2.094228506088257, 'learning_rate': 0.00012, 'epoch': 0.01}\n",
      "{'loss': 1.892, 'grad_norm': 1.8950233459472656, 'learning_rate': 0.00014, 'epoch': 0.01}\n",
      "{'loss': 1.9028, 'grad_norm': 1.8293263912200928, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 1.7341, 'grad_norm': 1.8322831392288208, 'learning_rate': 0.00018, 'epoch': 0.02}\n",
      "{'loss': 1.7392, 'grad_norm': 1.7804890871047974, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 1.3917, 'grad_norm': 1.875309944152832, 'learning_rate': 0.0001995918367346939, 'epoch': 0.02}\n",
      "{'loss': 1.4825, 'grad_norm': 2.3352768421173096, 'learning_rate': 0.00019918367346938775, 'epoch': 0.02}\n",
      "{'loss': 1.168, 'grad_norm': 1.8246804475784302, 'learning_rate': 0.00019877551020408164, 'epoch': 0.03}\n",
      "{'loss': 1.1522, 'grad_norm': 1.572745442390442, 'learning_rate': 0.00019836734693877553, 'epoch': 0.03}\n",
      "{'loss': 1.1686, 'grad_norm': 1.8667722940444946, 'learning_rate': 0.00019795918367346938, 'epoch': 0.03}\n",
      "{'loss': 1.2064, 'grad_norm': 1.9192206859588623, 'learning_rate': 0.00019755102040816327, 'epoch': 0.03}\n",
      "{'loss': 1.1204, 'grad_norm': 1.9289989471435547, 'learning_rate': 0.00019714285714285716, 'epoch': 0.03}\n",
      "{'loss': 0.9123, 'grad_norm': 1.6255617141723633, 'learning_rate': 0.00019673469387755104, 'epoch': 0.04}\n",
      "{'loss': 1.0138, 'grad_norm': 1.8015104532241821, 'learning_rate': 0.0001963265306122449, 'epoch': 0.04}\n",
      "{'loss': 1.134, 'grad_norm': 1.5938031673431396, 'learning_rate': 0.0001959183673469388, 'epoch': 0.04}\n",
      "{'loss': 1.1381, 'grad_norm': 1.770037055015564, 'learning_rate': 0.00019551020408163265, 'epoch': 0.04}\n",
      "{'loss': 1.2292, 'grad_norm': 1.8855708837509155, 'learning_rate': 0.00019510204081632656, 'epoch': 0.04}\n",
      "{'loss': 1.0034, 'grad_norm': 2.319880247116089, 'learning_rate': 0.00019469387755102042, 'epoch': 0.05}\n",
      "{'loss': 1.1881, 'grad_norm': 40.26081466674805, 'learning_rate': 0.0001942857142857143, 'epoch': 0.05}\n",
      "{'loss': 1.172, 'grad_norm': 5.82710075378418, 'learning_rate': 0.00019387755102040816, 'epoch': 0.05}\n",
      "{'loss': 1.0273, 'grad_norm': 2.1957602500915527, 'learning_rate': 0.00019346938775510205, 'epoch': 0.05}\n",
      "{'loss': 1.2775, 'grad_norm': 1.6895976066589355, 'learning_rate': 0.00019306122448979593, 'epoch': 0.05}\n",
      "{'loss': 1.2091, 'grad_norm': 1.6199172735214233, 'learning_rate': 0.0001926530612244898, 'epoch': 0.06}\n",
      "{'loss': 1.256, 'grad_norm': 1.678134560585022, 'learning_rate': 0.00019224489795918368, 'epoch': 0.06}\n",
      "{'loss': 0.9384, 'grad_norm': 1.6749181747436523, 'learning_rate': 0.00019183673469387756, 'epoch': 0.06}\n",
      "{'loss': 1.0361, 'grad_norm': 1.7314282655715942, 'learning_rate': 0.00019142857142857145, 'epoch': 0.06}\n",
      "{'loss': 1.4987, 'grad_norm': 1.9965317249298096, 'learning_rate': 0.0001910204081632653, 'epoch': 0.06}\n",
      "{'loss': 1.0028, 'grad_norm': 1.520471453666687, 'learning_rate': 0.0001906122448979592, 'epoch': 0.07}\n",
      "{'loss': 1.1735, 'grad_norm': 1.467056155204773, 'learning_rate': 0.00019020408163265305, 'epoch': 0.07}\n",
      "{'loss': 1.1097, 'grad_norm': 1.7979893684387207, 'learning_rate': 0.00018979591836734697, 'epoch': 0.07}\n",
      "{'loss': 0.9674, 'grad_norm': 1.318442463874817, 'learning_rate': 0.00018938775510204083, 'epoch': 0.07}\n",
      "{'loss': 0.9892, 'grad_norm': 1.5235209465026855, 'learning_rate': 0.0001889795918367347, 'epoch': 0.07}\n",
      "{'loss': 1.0829, 'grad_norm': 1.550398826599121, 'learning_rate': 0.00018857142857142857, 'epoch': 0.08}\n",
      "{'loss': 1.0074, 'grad_norm': 1.50758957862854, 'learning_rate': 0.00018816326530612246, 'epoch': 0.08}\n",
      "{'loss': 0.9452, 'grad_norm': 1.353467345237732, 'learning_rate': 0.00018775510204081634, 'epoch': 0.08}\n",
      "{'loss': 1.0122, 'grad_norm': 1.50874662399292, 'learning_rate': 0.00018734693877551023, 'epoch': 0.08}\n",
      "{'loss': 1.0776, 'grad_norm': 1.5516750812530518, 'learning_rate': 0.0001869387755102041, 'epoch': 0.08}\n",
      "{'loss': 1.0481, 'grad_norm': 1.6335216760635376, 'learning_rate': 0.00018653061224489797, 'epoch': 0.09}\n",
      "{'loss': 1.0146, 'grad_norm': 1.853318452835083, 'learning_rate': 0.00018612244897959183, 'epoch': 0.09}\n",
      "{'loss': 0.8578, 'grad_norm': 1.7626745700836182, 'learning_rate': 0.00018571428571428572, 'epoch': 0.09}\n",
      "{'loss': 1.1167, 'grad_norm': 1.7970020771026611, 'learning_rate': 0.0001853061224489796, 'epoch': 0.09}\n",
      "{'loss': 0.9386, 'grad_norm': 1.680127739906311, 'learning_rate': 0.00018489795918367346, 'epoch': 0.09}\n",
      "{'loss': 1.1141, 'grad_norm': 1.962034821510315, 'learning_rate': 0.00018448979591836735, 'epoch': 0.1}\n",
      "{'loss': 1.0754, 'grad_norm': 2.1415789127349854, 'learning_rate': 0.00018408163265306123, 'epoch': 0.1}\n",
      "{'loss': 1.0658, 'grad_norm': 1.8593695163726807, 'learning_rate': 0.00018367346938775512, 'epoch': 0.1}\n",
      "{'loss': 1.2261, 'grad_norm': 1.302927017211914, 'learning_rate': 0.00018326530612244898, 'epoch': 0.1}\n",
      "{'loss': 1.23, 'grad_norm': 1.2338837385177612, 'learning_rate': 0.00018285714285714286, 'epoch': 0.1}\n",
      "{'loss': 1.0383, 'grad_norm': 1.2643780708312988, 'learning_rate': 0.00018244897959183672, 'epoch': 0.11}\n",
      "{'loss': 1.1042, 'grad_norm': 1.317956566810608, 'learning_rate': 0.00018204081632653064, 'epoch': 0.11}\n",
      "{'loss': 1.0979, 'grad_norm': 1.3973417282104492, 'learning_rate': 0.0001816326530612245, 'epoch': 0.11}\n",
      "{'loss': 1.204, 'grad_norm': 1.472413420677185, 'learning_rate': 0.00018122448979591838, 'epoch': 0.11}\n",
      "{'loss': 1.2954, 'grad_norm': 1.3131741285324097, 'learning_rate': 0.00018081632653061224, 'epoch': 0.11}\n",
      "{'loss': 0.9117, 'grad_norm': 1.150615930557251, 'learning_rate': 0.00018040816326530615, 'epoch': 0.12}\n",
      "{'loss': 0.916, 'grad_norm': 1.2739616632461548, 'learning_rate': 0.00018, 'epoch': 0.12}\n",
      "{'loss': 1.066, 'grad_norm': 1.4361677169799805, 'learning_rate': 0.0001795918367346939, 'epoch': 0.12}\n",
      "{'loss': 1.0591, 'grad_norm': 1.3993977308273315, 'learning_rate': 0.00017918367346938776, 'epoch': 0.12}\n",
      "{'loss': 0.9612, 'grad_norm': 1.483891248703003, 'learning_rate': 0.00017877551020408164, 'epoch': 0.12}\n",
      "{'loss': 0.849, 'grad_norm': 1.828078031539917, 'learning_rate': 0.00017836734693877553, 'epoch': 0.13}\n",
      "{'loss': 0.8789, 'grad_norm': 1.9531255960464478, 'learning_rate': 0.0001779591836734694, 'epoch': 0.13}\n",
      "{'loss': 0.8906, 'grad_norm': 2.318100929260254, 'learning_rate': 0.00017755102040816327, 'epoch': 0.13}\n",
      "{'loss': 0.8694, 'grad_norm': 2.608834743499756, 'learning_rate': 0.00017714285714285713, 'epoch': 0.13}\n",
      "{'loss': 0.9093, 'grad_norm': 1.5531765222549438, 'learning_rate': 0.00017673469387755104, 'epoch': 0.13}\n",
      "{'loss': 0.8794, 'grad_norm': 1.7597436904907227, 'learning_rate': 0.0001763265306122449, 'epoch': 0.14}\n",
      "{'loss': 0.9034, 'grad_norm': 1.482979655265808, 'learning_rate': 0.0001759183673469388, 'epoch': 0.14}\n",
      "{'loss': 0.9829, 'grad_norm': 1.588975191116333, 'learning_rate': 0.00017551020408163265, 'epoch': 0.14}\n",
      "{'loss': 0.9665, 'grad_norm': 1.6832164525985718, 'learning_rate': 0.00017510204081632653, 'epoch': 0.14}\n",
      "{'loss': 0.8486, 'grad_norm': 1.5053411722183228, 'learning_rate': 0.00017469387755102042, 'epoch': 0.14}\n",
      "{'loss': 0.7064, 'grad_norm': 1.5501614809036255, 'learning_rate': 0.0001742857142857143, 'epoch': 0.15}\n",
      "{'loss': 0.8976, 'grad_norm': 1.9202347993850708, 'learning_rate': 0.00017387755102040816, 'epoch': 0.15}\n",
      "{'loss': 0.9247, 'grad_norm': 1.9476807117462158, 'learning_rate': 0.00017346938775510205, 'epoch': 0.15}\n",
      "{'loss': 0.9783, 'grad_norm': 2.014578342437744, 'learning_rate': 0.00017306122448979594, 'epoch': 0.15}\n",
      "{'loss': 0.9124, 'grad_norm': 1.974927544593811, 'learning_rate': 0.00017265306122448982, 'epoch': 0.15}\n",
      "{'loss': 0.9214, 'grad_norm': 2.1460046768188477, 'learning_rate': 0.00017224489795918368, 'epoch': 0.16}\n",
      "{'loss': 0.8346, 'grad_norm': 1.4190789461135864, 'learning_rate': 0.00017183673469387757, 'epoch': 0.16}\n",
      "{'loss': 1.0903, 'grad_norm': 2.064964771270752, 'learning_rate': 0.00017142857142857143, 'epoch': 0.16}\n",
      "{'loss': 1.0201, 'grad_norm': 1.8383897542953491, 'learning_rate': 0.0001710204081632653, 'epoch': 0.16}\n",
      "{'loss': 0.9335, 'grad_norm': 1.8856247663497925, 'learning_rate': 0.0001706122448979592, 'epoch': 0.16}\n",
      "{'loss': 0.6548, 'grad_norm': 1.794032335281372, 'learning_rate': 0.00017020408163265306, 'epoch': 0.17}\n",
      "{'loss': 0.8409, 'grad_norm': 1.6264517307281494, 'learning_rate': 0.00016979591836734694, 'epoch': 0.17}\n",
      "{'loss': 0.7521, 'grad_norm': 1.6090474128723145, 'learning_rate': 0.00016938775510204083, 'epoch': 0.17}\n",
      "{'loss': 0.644, 'grad_norm': 1.6054695844650269, 'learning_rate': 0.0001689795918367347, 'epoch': 0.17}\n",
      "{'loss': 0.6979, 'grad_norm': 1.4935319423675537, 'learning_rate': 0.00016857142857142857, 'epoch': 0.17}\n",
      "{'loss': 1.161, 'grad_norm': 2.0854358673095703, 'learning_rate': 0.00016816326530612246, 'epoch': 0.18}\n",
      "{'loss': 0.713, 'grad_norm': 1.5618456602096558, 'learning_rate': 0.00016775510204081632, 'epoch': 0.18}\n",
      "{'loss': 0.8283, 'grad_norm': 1.787673830986023, 'learning_rate': 0.00016734693877551023, 'epoch': 0.18}\n",
      "{'loss': 0.856, 'grad_norm': 1.8017436265945435, 'learning_rate': 0.0001669387755102041, 'epoch': 0.18}\n",
      "{'loss': 0.8232, 'grad_norm': 1.6385554075241089, 'learning_rate': 0.00016653061224489797, 'epoch': 0.18}\n",
      "{'loss': 0.9122, 'grad_norm': 1.7985939979553223, 'learning_rate': 0.00016612244897959183, 'epoch': 0.19}\n",
      "{'loss': 0.9323, 'grad_norm': 1.7855110168457031, 'learning_rate': 0.00016571428571428575, 'epoch': 0.19}\n",
      "{'loss': 0.6135, 'grad_norm': 1.637880802154541, 'learning_rate': 0.0001653061224489796, 'epoch': 0.19}\n",
      "{'loss': 0.7096, 'grad_norm': 1.767953872680664, 'learning_rate': 0.0001648979591836735, 'epoch': 0.19}\n",
      "{'loss': 0.6906, 'grad_norm': 1.4105433225631714, 'learning_rate': 0.00016448979591836735, 'epoch': 0.19}\n",
      "{'loss': 0.5894, 'grad_norm': 1.6194623708724976, 'learning_rate': 0.00016408163265306124, 'epoch': 0.2}\n",
      "{'loss': 0.6666, 'grad_norm': 1.7504736185073853, 'learning_rate': 0.00016367346938775512, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7397, 'grad_norm': 1.674275517463684, 'learning_rate': 0.00016326530612244898, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c77a98fd5624d369b1d1909da43178d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8313841223716736, 'eval_runtime': 313.1203, 'eval_samples_per_second': 0.639, 'eval_steps_per_second': 0.639, 'epoch': 0.2}\n",
      "{'loss': 0.9913, 'grad_norm': 1.3730859756469727, 'learning_rate': 0.00016285714285714287, 'epoch': 0.2}\n",
      "{'loss': 1.0093, 'grad_norm': 1.4525246620178223, 'learning_rate': 0.00016244897959183672, 'epoch': 0.2}\n",
      "{'loss': 0.9676, 'grad_norm': 1.4860512018203735, 'learning_rate': 0.0001620408163265306, 'epoch': 0.21}\n",
      "{'loss': 0.8492, 'grad_norm': 1.4372987747192383, 'learning_rate': 0.0001616326530612245, 'epoch': 0.21}\n",
      "{'loss': 0.9815, 'grad_norm': 1.3986963033676147, 'learning_rate': 0.00016122448979591838, 'epoch': 0.21}\n",
      "{'loss': 1.1081, 'grad_norm': 1.4276353120803833, 'learning_rate': 0.00016081632653061224, 'epoch': 0.21}\n",
      "{'loss': 0.7283, 'grad_norm': 1.203935980796814, 'learning_rate': 0.00016040816326530613, 'epoch': 0.21}\n",
      "{'loss': 0.8333, 'grad_norm': 1.2762736082077026, 'learning_rate': 0.00016, 'epoch': 0.22}\n",
      "{'loss': 0.9809, 'grad_norm': 1.3150049448013306, 'learning_rate': 0.0001595918367346939, 'epoch': 0.22}\n",
      "{'loss': 0.9106, 'grad_norm': 1.378116250038147, 'learning_rate': 0.00015918367346938776, 'epoch': 0.22}\n",
      "{'loss': 0.7672, 'grad_norm': 1.1969999074935913, 'learning_rate': 0.00015877551020408164, 'epoch': 0.22}\n",
      "{'loss': 0.9393, 'grad_norm': 1.4144978523254395, 'learning_rate': 0.0001583673469387755, 'epoch': 0.22}\n",
      "{'loss': 0.8688, 'grad_norm': 1.3483314514160156, 'learning_rate': 0.00015795918367346942, 'epoch': 0.23}\n",
      "{'loss': 0.8503, 'grad_norm': 1.4222161769866943, 'learning_rate': 0.00015755102040816327, 'epoch': 0.23}\n",
      "{'loss': 0.791, 'grad_norm': 1.4628885984420776, 'learning_rate': 0.00015714285714285716, 'epoch': 0.23}\n",
      "{'loss': 0.9034, 'grad_norm': 1.5695600509643555, 'learning_rate': 0.00015673469387755102, 'epoch': 0.23}\n",
      "{'loss': 0.8782, 'grad_norm': 1.430937647819519, 'learning_rate': 0.0001563265306122449, 'epoch': 0.23}\n",
      "{'loss': 0.9848, 'grad_norm': 1.4427616596221924, 'learning_rate': 0.0001559183673469388, 'epoch': 0.24}\n",
      "{'loss': 0.8462, 'grad_norm': 1.851845622062683, 'learning_rate': 0.00015551020408163265, 'epoch': 0.24}\n",
      "{'loss': 0.8888, 'grad_norm': 1.3080633878707886, 'learning_rate': 0.00015510204081632654, 'epoch': 0.24}\n",
      "{'loss': 0.7588, 'grad_norm': 1.2252718210220337, 'learning_rate': 0.0001546938775510204, 'epoch': 0.24}\n",
      "{'loss': 0.933, 'grad_norm': 1.4848078489303589, 'learning_rate': 0.0001542857142857143, 'epoch': 0.24}\n",
      "{'loss': 0.6877, 'grad_norm': 1.396216869354248, 'learning_rate': 0.00015387755102040817, 'epoch': 0.25}\n",
      "{'loss': 0.8063, 'grad_norm': 1.2804985046386719, 'learning_rate': 0.00015346938775510205, 'epoch': 0.25}\n",
      "{'loss': 0.7527, 'grad_norm': 1.2581686973571777, 'learning_rate': 0.0001530612244897959, 'epoch': 0.25}\n",
      "{'loss': 0.6817, 'grad_norm': 1.2619545459747314, 'learning_rate': 0.00015265306122448982, 'epoch': 0.25}\n",
      "{'loss': 1.0307, 'grad_norm': 1.6161640882492065, 'learning_rate': 0.00015224489795918368, 'epoch': 0.25}\n",
      "{'loss': 0.7246, 'grad_norm': 1.3703813552856445, 'learning_rate': 0.00015183673469387757, 'epoch': 0.26}\n",
      "{'loss': 0.6599, 'grad_norm': 1.310122013092041, 'learning_rate': 0.00015142857142857143, 'epoch': 0.26}\n",
      "{'loss': 0.7324, 'grad_norm': 1.340884804725647, 'learning_rate': 0.0001510204081632653, 'epoch': 0.26}\n",
      "{'loss': 0.7971, 'grad_norm': 1.3908425569534302, 'learning_rate': 0.0001506122448979592, 'epoch': 0.26}\n",
      "{'loss': 0.9533, 'grad_norm': 1.6750178337097168, 'learning_rate': 0.00015020408163265306, 'epoch': 0.26}\n",
      "{'loss': 0.6573, 'grad_norm': 1.2671945095062256, 'learning_rate': 0.00014979591836734694, 'epoch': 0.27}\n",
      "{'loss': 0.8405, 'grad_norm': 1.500405192375183, 'learning_rate': 0.00014938775510204083, 'epoch': 0.27}\n",
      "{'loss': 0.9989, 'grad_norm': 1.590135097503662, 'learning_rate': 0.00014897959183673472, 'epoch': 0.27}\n",
      "{'loss': 0.8079, 'grad_norm': 1.453471302986145, 'learning_rate': 0.00014857142857142857, 'epoch': 0.27}\n",
      "{'loss': 0.6928, 'grad_norm': 1.3230924606323242, 'learning_rate': 0.00014816326530612246, 'epoch': 0.27}\n",
      "{'loss': 0.9652, 'grad_norm': 1.6098129749298096, 'learning_rate': 0.00014775510204081632, 'epoch': 0.28}\n",
      "{'loss': 0.7735, 'grad_norm': 1.622968316078186, 'learning_rate': 0.0001473469387755102, 'epoch': 0.28}\n",
      "{'loss': 0.6682, 'grad_norm': 1.5934981107711792, 'learning_rate': 0.0001469387755102041, 'epoch': 0.28}\n",
      "{'loss': 0.5434, 'grad_norm': 1.2988369464874268, 'learning_rate': 0.00014653061224489798, 'epoch': 0.28}\n",
      "{'loss': 0.6287, 'grad_norm': 1.4304684400558472, 'learning_rate': 0.00014612244897959183, 'epoch': 0.28}\n",
      "{'loss': 0.643, 'grad_norm': 1.4390994310379028, 'learning_rate': 0.00014571428571428572, 'epoch': 0.29}\n",
      "{'loss': 0.6895, 'grad_norm': 1.599719762802124, 'learning_rate': 0.0001453061224489796, 'epoch': 0.29}\n",
      "{'loss': 0.6121, 'grad_norm': 1.4641753435134888, 'learning_rate': 0.0001448979591836735, 'epoch': 0.29}\n",
      "{'loss': 0.6917, 'grad_norm': 1.7276257276535034, 'learning_rate': 0.00014448979591836735, 'epoch': 0.29}\n",
      "{'loss': 0.646, 'grad_norm': 1.3841263055801392, 'learning_rate': 0.00014408163265306124, 'epoch': 0.29}\n",
      "{'loss': 0.7254, 'grad_norm': 1.6309852600097656, 'learning_rate': 0.0001436734693877551, 'epoch': 0.3}\n",
      "{'loss': 0.6453, 'grad_norm': 1.7564241886138916, 'learning_rate': 0.00014326530612244898, 'epoch': 0.3}\n",
      "{'loss': 0.6508, 'grad_norm': 1.8418829441070557, 'learning_rate': 0.00014285714285714287, 'epoch': 0.3}\n",
      "{'loss': 1.0293, 'grad_norm': 1.518435001373291, 'learning_rate': 0.00014244897959183673, 'epoch': 0.3}\n",
      "{'loss': 0.9436, 'grad_norm': 1.2131528854370117, 'learning_rate': 0.0001420408163265306, 'epoch': 0.3}\n",
      "{'loss': 0.6643, 'grad_norm': 1.0997200012207031, 'learning_rate': 0.0001416326530612245, 'epoch': 0.31}\n",
      "{'loss': 0.8422, 'grad_norm': 1.3421202898025513, 'learning_rate': 0.00014122448979591838, 'epoch': 0.31}\n",
      "{'loss': 0.6385, 'grad_norm': 1.262520670890808, 'learning_rate': 0.00014081632653061224, 'epoch': 0.31}\n",
      "{'loss': 0.8931, 'grad_norm': 1.4732484817504883, 'learning_rate': 0.00014040816326530613, 'epoch': 0.31}\n",
      "{'loss': 0.9667, 'grad_norm': 1.4169557094573975, 'learning_rate': 0.00014, 'epoch': 0.31}\n",
      "{'loss': 0.8363, 'grad_norm': 1.362115740776062, 'learning_rate': 0.0001395918367346939, 'epoch': 0.32}\n",
      "{'loss': 0.869, 'grad_norm': 1.3929319381713867, 'learning_rate': 0.00013918367346938776, 'epoch': 0.32}\n",
      "{'loss': 0.7909, 'grad_norm': 1.442842960357666, 'learning_rate': 0.00013877551020408165, 'epoch': 0.32}\n",
      "{'loss': 0.7271, 'grad_norm': 1.2925386428833008, 'learning_rate': 0.0001383673469387755, 'epoch': 0.32}\n",
      "{'loss': 0.7518, 'grad_norm': 1.3124756813049316, 'learning_rate': 0.00013795918367346942, 'epoch': 0.32}\n",
      "{'loss': 0.8003, 'grad_norm': 1.5005847215652466, 'learning_rate': 0.00013755102040816328, 'epoch': 0.33}\n",
      "{'loss': 0.6463, 'grad_norm': 1.3081737756729126, 'learning_rate': 0.00013714285714285716, 'epoch': 0.33}\n",
      "{'loss': 0.8508, 'grad_norm': 1.5277223587036133, 'learning_rate': 0.00013673469387755102, 'epoch': 0.33}\n",
      "{'loss': 0.9754, 'grad_norm': 1.4275511503219604, 'learning_rate': 0.0001363265306122449, 'epoch': 0.33}\n",
      "{'loss': 0.8293, 'grad_norm': 1.4699496030807495, 'learning_rate': 0.0001359183673469388, 'epoch': 0.33}\n",
      "{'loss': 0.8716, 'grad_norm': 1.32831609249115, 'learning_rate': 0.00013551020408163265, 'epoch': 0.34}\n",
      "{'loss': 0.7282, 'grad_norm': 1.3398432731628418, 'learning_rate': 0.00013510204081632654, 'epoch': 0.34}\n",
      "{'loss': 0.7058, 'grad_norm': 1.296184778213501, 'learning_rate': 0.0001346938775510204, 'epoch': 0.34}\n",
      "{'loss': 0.703, 'grad_norm': 1.4191279411315918, 'learning_rate': 0.00013428571428571428, 'epoch': 0.34}\n",
      "{'loss': 0.8798, 'grad_norm': 1.5553549528121948, 'learning_rate': 0.00013387755102040817, 'epoch': 0.34}\n",
      "{'loss': 0.7994, 'grad_norm': 1.3014116287231445, 'learning_rate': 0.00013346938775510205, 'epoch': 0.35}\n",
      "{'loss': 0.6763, 'grad_norm': 1.349096655845642, 'learning_rate': 0.0001330612244897959, 'epoch': 0.35}\n",
      "{'loss': 0.6991, 'grad_norm': 1.4833639860153198, 'learning_rate': 0.0001326530612244898, 'epoch': 0.35}\n",
      "{'loss': 0.8596, 'grad_norm': 1.723088026046753, 'learning_rate': 0.00013224489795918368, 'epoch': 0.35}\n",
      "{'loss': 0.657, 'grad_norm': 1.4594206809997559, 'learning_rate': 0.00013183673469387757, 'epoch': 0.35}\n",
      "{'loss': 0.7462, 'grad_norm': 1.4663718938827515, 'learning_rate': 0.00013142857142857143, 'epoch': 0.36}\n",
      "{'loss': 0.7543, 'grad_norm': 1.5127639770507812, 'learning_rate': 0.00013102040816326531, 'epoch': 0.36}\n",
      "{'loss': 0.7554, 'grad_norm': 1.5300276279449463, 'learning_rate': 0.00013061224489795917, 'epoch': 0.36}\n",
      "{'loss': 0.6694, 'grad_norm': 1.3514212369918823, 'learning_rate': 0.00013020408163265309, 'epoch': 0.36}\n",
      "{'loss': 0.6547, 'grad_norm': 1.3226667642593384, 'learning_rate': 0.00012979591836734695, 'epoch': 0.36}\n",
      "{'loss': 0.6415, 'grad_norm': 1.3494155406951904, 'learning_rate': 0.00012938775510204083, 'epoch': 0.37}\n",
      "{'loss': 0.8844, 'grad_norm': 1.6130532026290894, 'learning_rate': 0.0001289795918367347, 'epoch': 0.37}\n",
      "{'loss': 0.7234, 'grad_norm': 1.4494524002075195, 'learning_rate': 0.00012857142857142858, 'epoch': 0.37}\n",
      "{'loss': 0.8454, 'grad_norm': 1.45159113407135, 'learning_rate': 0.00012816326530612246, 'epoch': 0.37}\n",
      "{'loss': 0.6467, 'grad_norm': 1.3688685894012451, 'learning_rate': 0.00012775510204081632, 'epoch': 0.37}\n",
      "{'loss': 0.5723, 'grad_norm': 1.2735241651535034, 'learning_rate': 0.0001273469387755102, 'epoch': 0.38}\n",
      "{'loss': 0.5439, 'grad_norm': 1.2687532901763916, 'learning_rate': 0.00012693877551020406, 'epoch': 0.38}\n",
      "{'loss': 0.5449, 'grad_norm': 1.204254150390625, 'learning_rate': 0.00012653061224489798, 'epoch': 0.38}\n",
      "{'loss': 0.5941, 'grad_norm': 1.3792028427124023, 'learning_rate': 0.00012612244897959184, 'epoch': 0.38}\n",
      "{'loss': 0.6543, 'grad_norm': 1.4777884483337402, 'learning_rate': 0.00012571428571428572, 'epoch': 0.38}\n",
      "{'loss': 0.8435, 'grad_norm': 1.5656156539916992, 'learning_rate': 0.00012530612244897958, 'epoch': 0.39}\n",
      "{'loss': 0.6693, 'grad_norm': 1.4236595630645752, 'learning_rate': 0.0001248979591836735, 'epoch': 0.39}\n",
      "{'loss': 0.6021, 'grad_norm': 1.5897510051727295, 'learning_rate': 0.00012448979591836735, 'epoch': 0.39}\n",
      "{'loss': 0.5399, 'grad_norm': 1.356281042098999, 'learning_rate': 0.00012408163265306124, 'epoch': 0.39}\n",
      "{'loss': 0.533, 'grad_norm': 1.3291709423065186, 'learning_rate': 0.0001236734693877551, 'epoch': 0.39}\n",
      "{'loss': 0.7942, 'grad_norm': 1.887934684753418, 'learning_rate': 0.00012326530612244898, 'epoch': 0.4}\n",
      "{'loss': 0.5412, 'grad_norm': 1.5750150680541992, 'learning_rate': 0.00012285714285714287, 'epoch': 0.4}\n",
      "{'loss': 0.5368, 'grad_norm': 1.5157219171524048, 'learning_rate': 0.00012244897959183676, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9352b410e81847b0aaa9f0fd9dfec90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7442681789398193, 'eval_runtime': 312.994, 'eval_samples_per_second': 0.639, 'eval_steps_per_second': 0.639, 'epoch': 0.4}\n",
      "{'loss': 0.8356, 'grad_norm': 0.982948362827301, 'learning_rate': 0.00012204081632653061, 'epoch': 0.4}\n",
      "{'loss': 0.9199, 'grad_norm': 1.1370668411254883, 'learning_rate': 0.00012163265306122449, 'epoch': 0.4}\n",
      "{'loss': 0.7124, 'grad_norm': 1.0952026844024658, 'learning_rate': 0.00012122448979591839, 'epoch': 0.41}\n",
      "{'loss': 0.6102, 'grad_norm': 1.064613938331604, 'learning_rate': 0.00012081632653061226, 'epoch': 0.41}\n",
      "{'loss': 0.8999, 'grad_norm': 1.1580567359924316, 'learning_rate': 0.00012040816326530613, 'epoch': 0.41}\n",
      "{'loss': 0.9553, 'grad_norm': 1.3464362621307373, 'learning_rate': 0.00012, 'epoch': 0.41}\n",
      "{'loss': 0.7997, 'grad_norm': 1.322442889213562, 'learning_rate': 0.00011959183673469388, 'epoch': 0.41}\n",
      "{'loss': 0.91, 'grad_norm': 1.178346037864685, 'learning_rate': 0.00011918367346938777, 'epoch': 0.42}\n",
      "{'loss': 0.7453, 'grad_norm': 1.101326823234558, 'learning_rate': 0.00011877551020408165, 'epoch': 0.42}\n",
      "{'loss': 0.6851, 'grad_norm': 1.2089860439300537, 'learning_rate': 0.00011836734693877552, 'epoch': 0.42}\n",
      "{'loss': 0.6858, 'grad_norm': 1.0363967418670654, 'learning_rate': 0.00011795918367346939, 'epoch': 0.42}\n",
      "{'loss': 0.9982, 'grad_norm': 1.2650076150894165, 'learning_rate': 0.00011755102040816328, 'epoch': 0.42}\n",
      "{'loss': 0.669, 'grad_norm': 1.218188762664795, 'learning_rate': 0.00011714285714285715, 'epoch': 0.43}\n",
      "{'loss': 0.6831, 'grad_norm': 1.1856852769851685, 'learning_rate': 0.00011673469387755102, 'epoch': 0.43}\n",
      "{'loss': 0.8809, 'grad_norm': 1.2478199005126953, 'learning_rate': 0.0001163265306122449, 'epoch': 0.43}\n",
      "{'loss': 0.8361, 'grad_norm': 1.3030281066894531, 'learning_rate': 0.00011591836734693877, 'epoch': 0.43}\n",
      "{'loss': 0.8385, 'grad_norm': 1.5296794176101685, 'learning_rate': 0.00011551020408163267, 'epoch': 0.43}\n",
      "{'loss': 0.7154, 'grad_norm': 1.3075892925262451, 'learning_rate': 0.00011510204081632654, 'epoch': 0.44}\n",
      "{'loss': 0.7682, 'grad_norm': 1.354009747505188, 'learning_rate': 0.00011469387755102041, 'epoch': 0.44}\n",
      "{'loss': 0.7251, 'grad_norm': 1.4639408588409424, 'learning_rate': 0.00011428571428571428, 'epoch': 0.44}\n",
      "{'loss': 0.8335, 'grad_norm': 1.3990834951400757, 'learning_rate': 0.00011387755102040818, 'epoch': 0.44}\n",
      "{'loss': 0.8086, 'grad_norm': 1.6482011079788208, 'learning_rate': 0.00011346938775510206, 'epoch': 0.44}\n",
      "{'loss': 0.6448, 'grad_norm': 1.2726173400878906, 'learning_rate': 0.00011306122448979593, 'epoch': 0.45}\n",
      "{'loss': 0.9851, 'grad_norm': 1.5874650478363037, 'learning_rate': 0.0001126530612244898, 'epoch': 0.45}\n",
      "{'loss': 0.8658, 'grad_norm': 1.4480329751968384, 'learning_rate': 0.00011224489795918367, 'epoch': 0.45}\n",
      "{'loss': 0.7346, 'grad_norm': 1.186415433883667, 'learning_rate': 0.00011183673469387757, 'epoch': 0.45}\n",
      "{'loss': 0.7048, 'grad_norm': 1.3520485162734985, 'learning_rate': 0.00011142857142857144, 'epoch': 0.45}\n",
      "{'loss': 0.6192, 'grad_norm': 1.299686312675476, 'learning_rate': 0.00011102040816326532, 'epoch': 0.46}\n",
      "{'loss': 0.717, 'grad_norm': 1.29005765914917, 'learning_rate': 0.00011061224489795919, 'epoch': 0.46}\n",
      "{'loss': 0.8036, 'grad_norm': 1.3169631958007812, 'learning_rate': 0.00011020408163265306, 'epoch': 0.46}\n",
      "{'loss': 0.5779, 'grad_norm': 1.495704174041748, 'learning_rate': 0.00010979591836734695, 'epoch': 0.46}\n",
      "{'loss': 0.4963, 'grad_norm': 1.2206097841262817, 'learning_rate': 0.00010938775510204082, 'epoch': 0.46}\n",
      "{'loss': 0.9056, 'grad_norm': 1.3856226205825806, 'learning_rate': 0.00010897959183673469, 'epoch': 0.47}\n",
      "{'loss': 0.6301, 'grad_norm': 1.3108999729156494, 'learning_rate': 0.00010857142857142856, 'epoch': 0.47}\n",
      "{'loss': 0.7036, 'grad_norm': 1.5318459272384644, 'learning_rate': 0.00010816326530612246, 'epoch': 0.47}\n",
      "{'loss': 0.5677, 'grad_norm': 1.3125801086425781, 'learning_rate': 0.00010775510204081634, 'epoch': 0.47}\n",
      "{'loss': 0.667, 'grad_norm': 1.490114450454712, 'learning_rate': 0.00010734693877551021, 'epoch': 0.47}\n",
      "{'loss': 0.6526, 'grad_norm': 1.253596305847168, 'learning_rate': 0.00010693877551020408, 'epoch': 0.48}\n",
      "{'loss': 0.8206, 'grad_norm': 1.6531606912612915, 'learning_rate': 0.00010653061224489795, 'epoch': 0.48}\n",
      "{'loss': 0.7043, 'grad_norm': 1.3822815418243408, 'learning_rate': 0.00010612244897959185, 'epoch': 0.48}\n",
      "{'loss': 0.7004, 'grad_norm': 1.402261734008789, 'learning_rate': 0.00010571428571428572, 'epoch': 0.48}\n",
      "{'loss': 0.6769, 'grad_norm': 1.3889516592025757, 'learning_rate': 0.0001053061224489796, 'epoch': 0.48}\n",
      "{'loss': 0.7387, 'grad_norm': 1.5674340724945068, 'learning_rate': 0.00010489795918367347, 'epoch': 0.49}\n",
      "{'loss': 0.5492, 'grad_norm': 1.2594836950302124, 'learning_rate': 0.00010448979591836735, 'epoch': 0.49}\n",
      "{'loss': 0.9268, 'grad_norm': 1.770586371421814, 'learning_rate': 0.00010408163265306123, 'epoch': 0.49}\n",
      "{'loss': 0.6156, 'grad_norm': 1.3400366306304932, 'learning_rate': 0.00010367346938775511, 'epoch': 0.49}\n",
      "{'loss': 0.5623, 'grad_norm': 1.3555903434753418, 'learning_rate': 0.00010326530612244899, 'epoch': 0.49}\n",
      "{'loss': 0.5812, 'grad_norm': 1.372035264968872, 'learning_rate': 0.00010285714285714286, 'epoch': 0.5}\n",
      "{'loss': 0.6931, 'grad_norm': 1.6838350296020508, 'learning_rate': 0.00010244897959183674, 'epoch': 0.5}\n",
      "{'loss': 0.6589, 'grad_norm': 1.7994247674942017, 'learning_rate': 0.00010204081632653062, 'epoch': 0.5}\n",
      "{'loss': 0.9573, 'grad_norm': 1.1617321968078613, 'learning_rate': 0.00010163265306122449, 'epoch': 0.5}\n",
      "{'loss': 0.9226, 'grad_norm': 1.173163652420044, 'learning_rate': 0.00010122448979591836, 'epoch': 0.5}\n",
      "{'loss': 0.911, 'grad_norm': 1.2355841398239136, 'learning_rate': 0.00010081632653061226, 'epoch': 0.51}\n",
      "{'loss': 0.8267, 'grad_norm': 1.1714214086532593, 'learning_rate': 0.00010040816326530613, 'epoch': 0.51}\n",
      "{'loss': 0.9119, 'grad_norm': 1.2484171390533447, 'learning_rate': 0.0001, 'epoch': 0.51}\n",
      "{'loss': 0.7239, 'grad_norm': 1.1439381837844849, 'learning_rate': 9.959183673469388e-05, 'epoch': 0.51}\n",
      "{'loss': 0.8003, 'grad_norm': 1.096867561340332, 'learning_rate': 9.918367346938776e-05, 'epoch': 0.51}\n",
      "{'loss': 0.7384, 'grad_norm': 1.0946152210235596, 'learning_rate': 9.877551020408164e-05, 'epoch': 0.52}\n",
      "{'loss': 0.7545, 'grad_norm': 1.0902023315429688, 'learning_rate': 9.836734693877552e-05, 'epoch': 0.52}\n",
      "{'loss': 0.654, 'grad_norm': 1.0903308391571045, 'learning_rate': 9.79591836734694e-05, 'epoch': 0.52}\n",
      "{'loss': 0.6916, 'grad_norm': 1.1805371046066284, 'learning_rate': 9.755102040816328e-05, 'epoch': 0.52}\n",
      "{'loss': 0.8027, 'grad_norm': 1.184714674949646, 'learning_rate': 9.714285714285715e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5402, 'grad_norm': 0.9772195219993591, 'learning_rate': 9.673469387755102e-05, 'epoch': 0.53}\n",
      "{'loss': 0.7627, 'grad_norm': 1.2503756284713745, 'learning_rate': 9.63265306122449e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6994, 'grad_norm': 1.1821129322052002, 'learning_rate': 9.591836734693878e-05, 'epoch': 0.53}\n",
      "{'loss': 0.596, 'grad_norm': 1.196618676185608, 'learning_rate': 9.551020408163265e-05, 'epoch': 0.53}\n",
      "{'loss': 0.5641, 'grad_norm': 1.1406471729278564, 'learning_rate': 9.510204081632653e-05, 'epoch': 0.53}\n",
      "{'loss': 0.7117, 'grad_norm': 1.2432827949523926, 'learning_rate': 9.469387755102041e-05, 'epoch': 0.54}\n",
      "{'loss': 0.8569, 'grad_norm': 1.286439061164856, 'learning_rate': 9.428571428571429e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6061, 'grad_norm': 1.2092996835708618, 'learning_rate': 9.387755102040817e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6429, 'grad_norm': 1.1849502325057983, 'learning_rate': 9.346938775510204e-05, 'epoch': 0.54}\n",
      "{'loss': 0.761, 'grad_norm': 1.2248027324676514, 'learning_rate': 9.306122448979592e-05, 'epoch': 0.54}\n",
      "{'loss': 0.9226, 'grad_norm': 1.4247969388961792, 'learning_rate': 9.26530612244898e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7084, 'grad_norm': 1.3028569221496582, 'learning_rate': 9.224489795918367e-05, 'epoch': 0.55}\n",
      "{'loss': 0.713, 'grad_norm': 1.3643618822097778, 'learning_rate': 9.183673469387756e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7155, 'grad_norm': 1.310920000076294, 'learning_rate': 9.142857142857143e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7631, 'grad_norm': 1.3577557802200317, 'learning_rate': 9.102040816326532e-05, 'epoch': 0.55}\n",
      "{'loss': 0.6596, 'grad_norm': 1.255486011505127, 'learning_rate': 9.061224489795919e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6814, 'grad_norm': 1.2906489372253418, 'learning_rate': 9.020408163265308e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6333, 'grad_norm': 1.353478193283081, 'learning_rate': 8.979591836734695e-05, 'epoch': 0.56}\n",
      "{'loss': 0.7588, 'grad_norm': 1.3603615760803223, 'learning_rate': 8.938775510204082e-05, 'epoch': 0.56}\n",
      "{'loss': 0.7834, 'grad_norm': 1.4130589962005615, 'learning_rate': 8.89795918367347e-05, 'epoch': 0.56}\n",
      "{'loss': 0.7471, 'grad_norm': 1.3341519832611084, 'learning_rate': 8.857142857142857e-05, 'epoch': 0.57}\n",
      "{'loss': 0.7618, 'grad_norm': 1.3989510536193848, 'learning_rate': 8.816326530612245e-05, 'epoch': 0.57}\n",
      "{'loss': 0.9106, 'grad_norm': 1.3706201314926147, 'learning_rate': 8.775510204081632e-05, 'epoch': 0.57}\n",
      "{'loss': 0.728, 'grad_norm': 1.2666505575180054, 'learning_rate': 8.734693877551021e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6712, 'grad_norm': 1.252532720565796, 'learning_rate': 8.693877551020408e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5942, 'grad_norm': 1.1336584091186523, 'learning_rate': 8.653061224489797e-05, 'epoch': 0.58}\n",
      "{'loss': 0.7587, 'grad_norm': 1.2631081342697144, 'learning_rate': 8.612244897959184e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6166, 'grad_norm': 1.2752715349197388, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6322, 'grad_norm': 1.2097947597503662, 'learning_rate': 8.53061224489796e-05, 'epoch': 0.58}\n",
      "{'loss': 0.5242, 'grad_norm': 1.1310758590698242, 'learning_rate': 8.489795918367347e-05, 'epoch': 0.58}\n",
      "{'loss': 0.5035, 'grad_norm': 1.1740097999572754, 'learning_rate': 8.448979591836736e-05, 'epoch': 0.59}\n",
      "{'loss': 0.8656, 'grad_norm': 1.5684019327163696, 'learning_rate': 8.408163265306123e-05, 'epoch': 0.59}\n",
      "{'loss': 0.6689, 'grad_norm': 1.3778042793273926, 'learning_rate': 8.367346938775511e-05, 'epoch': 0.59}\n",
      "{'loss': 0.6633, 'grad_norm': 1.395592212677002, 'learning_rate': 8.326530612244899e-05, 'epoch': 0.59}\n",
      "{'loss': 0.5358, 'grad_norm': 1.2544832229614258, 'learning_rate': 8.285714285714287e-05, 'epoch': 0.59}\n",
      "{'loss': 0.6654, 'grad_norm': 1.5659812688827515, 'learning_rate': 8.244897959183675e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5288, 'grad_norm': 1.4398573637008667, 'learning_rate': 8.204081632653062e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5858, 'grad_norm': 1.599420428276062, 'learning_rate': 8.163265306122449e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c61258e31b14593b43eccad68a413bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6832824945449829, 'eval_runtime': 313.4846, 'eval_samples_per_second': 0.638, 'eval_steps_per_second': 0.638, 'epoch': 0.6}\n",
      "{'loss': 0.9097, 'grad_norm': 1.2077662944793701, 'learning_rate': 8.122448979591836e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6523, 'grad_norm': 1.236101508140564, 'learning_rate': 8.081632653061225e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6809, 'grad_norm': 1.152949333190918, 'learning_rate': 8.040816326530612e-05, 'epoch': 0.61}\n",
      "{'loss': 0.9238, 'grad_norm': 1.2751764059066772, 'learning_rate': 8e-05, 'epoch': 0.61}\n",
      "{'loss': 0.641, 'grad_norm': 1.1590347290039062, 'learning_rate': 7.959183673469388e-05, 'epoch': 0.61}\n",
      "{'loss': 0.697, 'grad_norm': 1.2468140125274658, 'learning_rate': 7.918367346938775e-05, 'epoch': 0.61}\n",
      "{'loss': 0.743, 'grad_norm': 1.356968879699707, 'learning_rate': 7.877551020408164e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6193, 'grad_norm': 1.267921805381775, 'learning_rate': 7.836734693877551e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6416, 'grad_norm': 1.409745216369629, 'learning_rate': 7.79591836734694e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6342, 'grad_norm': 1.1838090419769287, 'learning_rate': 7.755102040816327e-05, 'epoch': 0.62}\n",
      "{'loss': 0.601, 'grad_norm': 1.3061342239379883, 'learning_rate': 7.714285714285715e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6477, 'grad_norm': 1.2202329635620117, 'learning_rate': 7.673469387755103e-05, 'epoch': 0.62}\n",
      "{'loss': 0.8764, 'grad_norm': 1.3976141214370728, 'learning_rate': 7.632653061224491e-05, 'epoch': 0.63}\n",
      "{'loss': 0.7396, 'grad_norm': 1.277173399925232, 'learning_rate': 7.591836734693878e-05, 'epoch': 0.63}\n",
      "{'loss': 0.7433, 'grad_norm': 1.239951252937317, 'learning_rate': 7.551020408163266e-05, 'epoch': 0.63}\n",
      "{'loss': 0.7516, 'grad_norm': 1.3447823524475098, 'learning_rate': 7.510204081632653e-05, 'epoch': 0.63}\n",
      "{'loss': 0.7492, 'grad_norm': 1.2029706239700317, 'learning_rate': 7.469387755102041e-05, 'epoch': 0.63}\n",
      "{'loss': 0.6915, 'grad_norm': 1.3076090812683105, 'learning_rate': 7.428571428571429e-05, 'epoch': 0.64}\n",
      "{'loss': 0.6093, 'grad_norm': 1.3754266500473022, 'learning_rate': 7.387755102040816e-05, 'epoch': 0.64}\n",
      "{'loss': 0.6016, 'grad_norm': 1.0449459552764893, 'learning_rate': 7.346938775510205e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7011, 'grad_norm': 1.241784691810608, 'learning_rate': 7.306122448979592e-05, 'epoch': 0.64}\n",
      "{'loss': 0.5717, 'grad_norm': 1.1204583644866943, 'learning_rate': 7.26530612244898e-05, 'epoch': 0.64}\n",
      "{'loss': 0.6331, 'grad_norm': 1.2027857303619385, 'learning_rate': 7.224489795918368e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7224, 'grad_norm': 1.3357995748519897, 'learning_rate': 7.183673469387755e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6753, 'grad_norm': 1.2472032308578491, 'learning_rate': 7.142857142857143e-05, 'epoch': 0.65}\n",
      "{'loss': 0.754, 'grad_norm': 1.4811906814575195, 'learning_rate': 7.10204081632653e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6926, 'grad_norm': 1.3377717733383179, 'learning_rate': 7.061224489795919e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7729, 'grad_norm': 1.441169023513794, 'learning_rate': 7.020408163265306e-05, 'epoch': 0.66}\n",
      "{'loss': 0.7372, 'grad_norm': 1.3788211345672607, 'learning_rate': 6.979591836734695e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6757, 'grad_norm': 1.2877321243286133, 'learning_rate': 6.938775510204082e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6231, 'grad_norm': 1.2817350625991821, 'learning_rate': 6.897959183673471e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6138, 'grad_norm': 1.265518307685852, 'learning_rate': 6.857142857142858e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5859, 'grad_norm': 1.191991925239563, 'learning_rate': 6.816326530612245e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6322, 'grad_norm': 1.2113349437713623, 'learning_rate': 6.775510204081633e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6296, 'grad_norm': 1.4079947471618652, 'learning_rate': 6.73469387755102e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5147, 'grad_norm': 1.227812647819519, 'learning_rate': 6.693877551020408e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6689, 'grad_norm': 1.462931513786316, 'learning_rate': 6.653061224489796e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5575, 'grad_norm': 1.1698009967803955, 'learning_rate': 6.612244897959184e-05, 'epoch': 0.68}\n",
      "{'loss': 0.6326, 'grad_norm': 1.4299334287643433, 'learning_rate': 6.571428571428571e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4968, 'grad_norm': 1.2557101249694824, 'learning_rate': 6.530612244897959e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5037, 'grad_norm': 1.241654872894287, 'learning_rate': 6.489795918367347e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5411, 'grad_norm': 1.3063483238220215, 'learning_rate': 6.448979591836734e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5909, 'grad_norm': 1.7589561939239502, 'learning_rate': 6.408163265306123e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7398, 'grad_norm': 1.5783261060714722, 'learning_rate': 6.36734693877551e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4922, 'grad_norm': 1.3197911977767944, 'learning_rate': 6.326530612244899e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5176, 'grad_norm': 1.361831784248352, 'learning_rate': 6.285714285714286e-05, 'epoch': 0.69}\n",
      "{'loss': 0.6341, 'grad_norm': 1.6829169988632202, 'learning_rate': 6.244897959183675e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5432, 'grad_norm': 1.7940279245376587, 'learning_rate': 6.204081632653062e-05, 'epoch': 0.7}\n",
      "{'loss': 0.4748, 'grad_norm': 1.5679022073745728, 'learning_rate': 6.163265306122449e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6196, 'grad_norm': 1.8054765462875366, 'learning_rate': 6.122448979591838e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8545, 'grad_norm': 1.025660753250122, 'learning_rate': 6.081632653061224e-05, 'epoch': 0.7}\n",
      "{'loss': 0.873, 'grad_norm': 1.131756067276001, 'learning_rate': 6.040816326530613e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7625, 'grad_norm': 1.1139945983886719, 'learning_rate': 6e-05, 'epoch': 0.71}\n",
      "{'loss': 0.6202, 'grad_norm': 1.0238581895828247, 'learning_rate': 5.959183673469389e-05, 'epoch': 0.71}\n",
      "{'loss': 0.8677, 'grad_norm': 1.2440592050552368, 'learning_rate': 5.918367346938776e-05, 'epoch': 0.71}\n",
      "{'loss': 0.6751, 'grad_norm': 1.1705900430679321, 'learning_rate': 5.877551020408164e-05, 'epoch': 0.71}\n",
      "{'loss': 0.7368, 'grad_norm': 1.3105063438415527, 'learning_rate': 5.836734693877551e-05, 'epoch': 0.71}\n",
      "{'loss': 0.6547, 'grad_norm': 1.1869733333587646, 'learning_rate': 5.7959183673469384e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8133, 'grad_norm': 1.2665901184082031, 'learning_rate': 5.755102040816327e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7829, 'grad_norm': 1.2226057052612305, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8126, 'grad_norm': 1.2279934883117676, 'learning_rate': 5.673469387755103e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7206, 'grad_norm': 1.488430142402649, 'learning_rate': 5.63265306122449e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5536, 'grad_norm': 1.2207744121551514, 'learning_rate': 5.5918367346938786e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7777, 'grad_norm': 1.365208625793457, 'learning_rate': 5.551020408163266e-05, 'epoch': 0.73}\n",
      "{'loss': 0.8277, 'grad_norm': 1.3861100673675537, 'learning_rate': 5.510204081632653e-05, 'epoch': 0.73}\n",
      "{'loss': 0.6116, 'grad_norm': 1.2655833959579468, 'learning_rate': 5.469387755102041e-05, 'epoch': 0.73}\n",
      "{'loss': 0.6873, 'grad_norm': 1.3455170392990112, 'learning_rate': 5.428571428571428e-05, 'epoch': 0.73}\n",
      "{'loss': 0.712, 'grad_norm': 1.2383030652999878, 'learning_rate': 5.387755102040817e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7481, 'grad_norm': 1.4574215412139893, 'learning_rate': 5.346938775510204e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6622, 'grad_norm': 1.1943495273590088, 'learning_rate': 5.3061224489795926e-05, 'epoch': 0.74}\n",
      "{'loss': 0.71, 'grad_norm': 1.3744012117385864, 'learning_rate': 5.26530612244898e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7357, 'grad_norm': 1.424709439277649, 'learning_rate': 5.224489795918368e-05, 'epoch': 0.74}\n",
      "{'loss': 0.5148, 'grad_norm': 1.0971516370773315, 'learning_rate': 5.1836734693877557e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6024, 'grad_norm': 1.2746416330337524, 'learning_rate': 5.142857142857143e-05, 'epoch': 0.75}\n",
      "{'loss': 0.5634, 'grad_norm': 1.0905207395553589, 'learning_rate': 5.102040816326531e-05, 'epoch': 0.75}\n",
      "{'loss': 0.4643, 'grad_norm': 1.1981488466262817, 'learning_rate': 5.061224489795918e-05, 'epoch': 0.75}\n",
      "{'loss': 0.5747, 'grad_norm': 1.3021080493927002, 'learning_rate': 5.0204081632653066e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6771, 'grad_norm': 1.4717926979064941, 'learning_rate': 4.979591836734694e-05, 'epoch': 0.76}\n",
      "{'loss': 0.617, 'grad_norm': 1.4386838674545288, 'learning_rate': 4.938775510204082e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6612, 'grad_norm': 1.3872357606887817, 'learning_rate': 4.89795918367347e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8642, 'grad_norm': 1.742011308670044, 'learning_rate': 4.8571428571428576e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6175, 'grad_norm': 1.2916666269302368, 'learning_rate': 4.816326530612245e-05, 'epoch': 0.76}\n",
      "{'loss': 0.964, 'grad_norm': 1.5473735332489014, 'learning_rate': 4.775510204081633e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5778, 'grad_norm': 1.273012638092041, 'learning_rate': 4.7346938775510206e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5711, 'grad_norm': 1.3179980516433716, 'learning_rate': 4.6938775510204086e-05, 'epoch': 0.77}\n",
      "{'loss': 0.8944, 'grad_norm': 1.9195512533187866, 'learning_rate': 4.653061224489796e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6105, 'grad_norm': 1.3919905424118042, 'learning_rate': 4.612244897959184e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5142, 'grad_norm': 1.3187540769577026, 'learning_rate': 4.5714285714285716e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7057, 'grad_norm': 1.525630235671997, 'learning_rate': 4.5306122448979595e-05, 'epoch': 0.78}\n",
      "{'loss': 0.583, 'grad_norm': 1.5326249599456787, 'learning_rate': 4.4897959183673474e-05, 'epoch': 0.78}\n",
      "{'loss': 0.5958, 'grad_norm': 1.2794288396835327, 'learning_rate': 4.448979591836735e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6672, 'grad_norm': 1.566587209701538, 'learning_rate': 4.4081632653061226e-05, 'epoch': 0.78}\n",
      "{'loss': 0.51, 'grad_norm': 1.2972702980041504, 'learning_rate': 4.3673469387755105e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4689, 'grad_norm': 1.1500723361968994, 'learning_rate': 4.3265306122448984e-05, 'epoch': 0.79}\n",
      "{'loss': 0.6848, 'grad_norm': 1.385006308555603, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.79}\n",
      "{'loss': 0.5907, 'grad_norm': 1.4502639770507812, 'learning_rate': 4.2448979591836735e-05, 'epoch': 0.79}\n",
      "{'loss': 0.4928, 'grad_norm': 1.231950283050537, 'learning_rate': 4.2040816326530615e-05, 'epoch': 0.79}\n",
      "{'loss': 0.592, 'grad_norm': 1.591294527053833, 'learning_rate': 4.1632653061224494e-05, 'epoch': 0.8}\n",
      "{'loss': 0.5722, 'grad_norm': 1.6341116428375244, 'learning_rate': 4.122448979591837e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4486, 'grad_norm': 1.5828279256820679, 'learning_rate': 4.0816326530612245e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13abc1a760d64c9298169d862ecea180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6420578956604004, 'eval_runtime': 313.0002, 'eval_samples_per_second': 0.639, 'eval_steps_per_second': 0.639, 'epoch': 0.8}\n",
      "{'loss': 0.8117, 'grad_norm': 0.9699596166610718, 'learning_rate': 4.0408163265306124e-05, 'epoch': 0.8}\n",
      "{'loss': 0.8507, 'grad_norm': 0.972296416759491, 'learning_rate': 4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7629, 'grad_norm': 1.0452474355697632, 'learning_rate': 3.9591836734693876e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6485, 'grad_norm': 1.1325629949569702, 'learning_rate': 3.9183673469387755e-05, 'epoch': 0.81}\n",
      "{'loss': 0.8584, 'grad_norm': 1.2231523990631104, 'learning_rate': 3.8775510204081634e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6868, 'grad_norm': 1.1652140617370605, 'learning_rate': 3.836734693877551e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6327, 'grad_norm': 1.1628273725509644, 'learning_rate': 3.795918367346939e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6203, 'grad_norm': 1.1739225387573242, 'learning_rate': 3.7551020408163264e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7557, 'grad_norm': 1.2867625951766968, 'learning_rate': 3.7142857142857143e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5959, 'grad_norm': 1.0997471809387207, 'learning_rate': 3.673469387755102e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7403, 'grad_norm': 1.228541612625122, 'learning_rate': 3.63265306122449e-05, 'epoch': 0.82}\n",
      "{'loss': 0.9546, 'grad_norm': 1.5094330310821533, 'learning_rate': 3.5918367346938774e-05, 'epoch': 0.82}\n",
      "{'loss': 0.6669, 'grad_norm': 1.2552721500396729, 'learning_rate': 3.551020408163265e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7654, 'grad_norm': 1.348441481590271, 'learning_rate': 3.510204081632653e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8049, 'grad_norm': 1.46577787399292, 'learning_rate': 3.469387755102041e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5801, 'grad_norm': 1.1594338417053223, 'learning_rate': 3.428571428571429e-05, 'epoch': 0.83}\n",
      "{'loss': 1.0273, 'grad_norm': 1.504431962966919, 'learning_rate': 3.387755102040816e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7511, 'grad_norm': 1.4206188917160034, 'learning_rate': 3.346938775510204e-05, 'epoch': 0.84}\n",
      "{'loss': 0.5215, 'grad_norm': 1.160220742225647, 'learning_rate': 3.306122448979592e-05, 'epoch': 0.84}\n",
      "{'loss': 0.5936, 'grad_norm': 1.2046465873718262, 'learning_rate': 3.265306122448979e-05, 'epoch': 0.84}\n",
      "{'loss': 0.6192, 'grad_norm': 1.2203823328018188, 'learning_rate': 3.224489795918367e-05, 'epoch': 0.84}\n",
      "{'loss': 0.497, 'grad_norm': 1.1655609607696533, 'learning_rate': 3.183673469387755e-05, 'epoch': 0.84}\n",
      "{'loss': 0.6416, 'grad_norm': 1.2575610876083374, 'learning_rate': 3.142857142857143e-05, 'epoch': 0.85}\n",
      "{'loss': 0.5682, 'grad_norm': 1.2505195140838623, 'learning_rate': 3.102040816326531e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7677, 'grad_norm': 1.4835610389709473, 'learning_rate': 3.061224489795919e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7034, 'grad_norm': 1.3629889488220215, 'learning_rate': 3.0204081632653065e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6865, 'grad_norm': 1.2519292831420898, 'learning_rate': 2.9795918367346944e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6325, 'grad_norm': 1.1735515594482422, 'learning_rate': 2.938775510204082e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6845, 'grad_norm': 1.453681468963623, 'learning_rate': 2.8979591836734692e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7686, 'grad_norm': 1.3140316009521484, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6638, 'grad_norm': 1.3636183738708496, 'learning_rate': 2.816326530612245e-05, 'epoch': 0.86}\n",
      "{'loss': 0.672, 'grad_norm': 1.5202089548110962, 'learning_rate': 2.775510204081633e-05, 'epoch': 0.86}\n",
      "{'loss': 0.5865, 'grad_norm': 1.2484102249145508, 'learning_rate': 2.7346938775510205e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4687, 'grad_norm': 1.1446094512939453, 'learning_rate': 2.6938775510204084e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6968, 'grad_norm': 1.3835173845291138, 'learning_rate': 2.6530612244897963e-05, 'epoch': 0.87}\n",
      "{'loss': 0.5912, 'grad_norm': 1.2668559551239014, 'learning_rate': 2.612244897959184e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6254, 'grad_norm': 1.3235716819763184, 'learning_rate': 2.5714285714285714e-05, 'epoch': 0.87}\n",
      "{'loss': 0.5993, 'grad_norm': 1.198565125465393, 'learning_rate': 2.530612244897959e-05, 'epoch': 0.88}\n",
      "{'loss': 0.5734, 'grad_norm': 1.279863715171814, 'learning_rate': 2.489795918367347e-05, 'epoch': 0.88}\n",
      "{'loss': 0.6917, 'grad_norm': 1.6324964761734009, 'learning_rate': 2.448979591836735e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4815, 'grad_norm': 1.2418173551559448, 'learning_rate': 2.4081632653061224e-05, 'epoch': 0.88}\n",
      "{'loss': 0.6387, 'grad_norm': 1.3978908061981201, 'learning_rate': 2.3673469387755103e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4174, 'grad_norm': 1.1341410875320435, 'learning_rate': 2.326530612244898e-05, 'epoch': 0.89}\n",
      "{'loss': 0.6313, 'grad_norm': 1.408327341079712, 'learning_rate': 2.2857142857142858e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5294, 'grad_norm': 1.471867561340332, 'learning_rate': 2.2448979591836737e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5438, 'grad_norm': 1.208953857421875, 'learning_rate': 2.2040816326530613e-05, 'epoch': 0.89}\n",
      "{'loss': 0.6721, 'grad_norm': 1.614711046218872, 'learning_rate': 2.1632653061224492e-05, 'epoch': 0.89}\n",
      "{'loss': 0.6149, 'grad_norm': 1.5603015422821045, 'learning_rate': 2.1224489795918368e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5535, 'grad_norm': 1.3711882829666138, 'learning_rate': 2.0816326530612247e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5654, 'grad_norm': 1.457540512084961, 'learning_rate': 2.0408163265306123e-05, 'epoch': 0.9}\n",
      "{'loss': 0.6726, 'grad_norm': 0.8936583995819092, 'learning_rate': 2e-05, 'epoch': 0.9}\n",
      "{'loss': 0.6666, 'grad_norm': 1.0121190547943115, 'learning_rate': 1.9591836734693877e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5974, 'grad_norm': 0.9742965698242188, 'learning_rate': 1.9183673469387756e-05, 'epoch': 0.91}\n",
      "{'loss': 0.591, 'grad_norm': 1.1006416082382202, 'learning_rate': 1.8775510204081632e-05, 'epoch': 0.91}\n",
      "{'loss': 0.6108, 'grad_norm': 1.189452052116394, 'learning_rate': 1.836734693877551e-05, 'epoch': 0.91}\n",
      "{'loss': 0.6436, 'grad_norm': 1.2435532808303833, 'learning_rate': 1.7959183673469387e-05, 'epoch': 0.91}\n",
      "{'loss': 0.5573, 'grad_norm': 1.0582504272460938, 'learning_rate': 1.7551020408163266e-05, 'epoch': 0.91}\n",
      "{'loss': 0.5677, 'grad_norm': 1.1321029663085938, 'learning_rate': 1.7142857142857145e-05, 'epoch': 0.92}\n",
      "{'loss': 0.5514, 'grad_norm': 1.187497854232788, 'learning_rate': 1.673469387755102e-05, 'epoch': 0.92}\n",
      "{'loss': 0.5602, 'grad_norm': 1.0435539484024048, 'learning_rate': 1.6326530612244897e-05, 'epoch': 0.92}\n",
      "{'loss': 0.6167, 'grad_norm': 1.192624568939209, 'learning_rate': 1.5918367346938776e-05, 'epoch': 0.92}\n",
      "{'loss': 0.5705, 'grad_norm': 1.1151392459869385, 'learning_rate': 1.5510204081632655e-05, 'epoch': 0.92}\n",
      "{'loss': 0.5193, 'grad_norm': 1.1794242858886719, 'learning_rate': 1.5102040816326532e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7573, 'grad_norm': 1.2463740110397339, 'learning_rate': 1.469387755102041e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8247, 'grad_norm': 1.5559501647949219, 'learning_rate': 1.4285714285714285e-05, 'epoch': 0.93}\n",
      "{'loss': 0.5582, 'grad_norm': 1.2187520265579224, 'learning_rate': 1.3877551020408165e-05, 'epoch': 0.93}\n",
      "{'loss': 0.9365, 'grad_norm': 1.3913589715957642, 'learning_rate': 1.3469387755102042e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7051, 'grad_norm': 1.3286728858947754, 'learning_rate': 1.306122448979592e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6868, 'grad_norm': 1.2789865732192993, 'learning_rate': 1.2653061224489795e-05, 'epoch': 0.94}\n",
      "{'loss': 0.5465, 'grad_norm': 1.111632227897644, 'learning_rate': 1.2244897959183674e-05, 'epoch': 0.94}\n",
      "{'loss': 0.5599, 'grad_norm': 1.238206148147583, 'learning_rate': 1.1836734693877552e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6751, 'grad_norm': 1.314517617225647, 'learning_rate': 1.1428571428571429e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6437, 'grad_norm': 1.290793776512146, 'learning_rate': 1.1020408163265306e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5753, 'grad_norm': 1.1896028518676758, 'learning_rate': 1.0612244897959184e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5298, 'grad_norm': 1.1383322477340698, 'learning_rate': 1.0204081632653061e-05, 'epoch': 0.95}\n",
      "{'loss': 0.6973, 'grad_norm': 1.5532913208007812, 'learning_rate': 9.795918367346939e-06, 'epoch': 0.95}\n",
      "{'loss': 0.6963, 'grad_norm': 1.5721997022628784, 'learning_rate': 9.387755102040816e-06, 'epoch': 0.95}\n",
      "{'loss': 0.6371, 'grad_norm': 1.250964879989624, 'learning_rate': 8.979591836734694e-06, 'epoch': 0.96}\n",
      "{'loss': 0.6435, 'grad_norm': 1.3025412559509277, 'learning_rate': 8.571428571428573e-06, 'epoch': 0.96}\n",
      "{'loss': 0.4935, 'grad_norm': 1.1824909448623657, 'learning_rate': 8.163265306122448e-06, 'epoch': 0.96}\n",
      "{'loss': 0.7471, 'grad_norm': 1.5101929903030396, 'learning_rate': 7.755102040816327e-06, 'epoch': 0.96}\n",
      "{'loss': 0.5473, 'grad_norm': 1.296390175819397, 'learning_rate': 7.346938775510205e-06, 'epoch': 0.96}\n",
      "{'loss': 0.7454, 'grad_norm': 1.5108003616333008, 'learning_rate': 6.938775510204082e-06, 'epoch': 0.97}\n",
      "{'loss': 0.5189, 'grad_norm': 1.2840176820755005, 'learning_rate': 6.53061224489796e-06, 'epoch': 0.97}\n",
      "{'loss': 0.6136, 'grad_norm': 1.3814512491226196, 'learning_rate': 6.122448979591837e-06, 'epoch': 0.97}\n",
      "{'loss': 0.5332, 'grad_norm': 1.3241875171661377, 'learning_rate': 5.7142857142857145e-06, 'epoch': 0.97}\n",
      "{'loss': 0.5302, 'grad_norm': 1.234622836112976, 'learning_rate': 5.306122448979592e-06, 'epoch': 0.97}\n",
      "{'loss': 0.6393, 'grad_norm': 1.274903416633606, 'learning_rate': 4.897959183673469e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8198, 'grad_norm': 1.7572280168533325, 'learning_rate': 4.489795918367347e-06, 'epoch': 0.98}\n",
      "{'loss': 0.5032, 'grad_norm': 1.3113914728164673, 'learning_rate': 4.081632653061224e-06, 'epoch': 0.98}\n",
      "{'loss': 0.7617, 'grad_norm': 1.5347886085510254, 'learning_rate': 3.6734693877551024e-06, 'epoch': 0.98}\n",
      "{'loss': 0.5175, 'grad_norm': 1.2470136880874634, 'learning_rate': 3.26530612244898e-06, 'epoch': 0.98}\n",
      "{'loss': 0.5871, 'grad_norm': 1.4031239748001099, 'learning_rate': 2.8571428571428573e-06, 'epoch': 0.99}\n",
      "{'loss': 0.4735, 'grad_norm': 1.3400799036026, 'learning_rate': 2.4489795918367347e-06, 'epoch': 0.99}\n",
      "{'loss': 0.5548, 'grad_norm': 1.4019880294799805, 'learning_rate': 2.040816326530612e-06, 'epoch': 0.99}\n",
      "{'loss': 0.5225, 'grad_norm': 1.2637076377868652, 'learning_rate': 1.63265306122449e-06, 'epoch': 0.99}\n",
      "{'loss': 0.5443, 'grad_norm': 1.3758164644241333, 'learning_rate': 1.2244897959183673e-06, 'epoch': 0.99}\n",
      "{'loss': 0.5057, 'grad_norm': 1.7719134092330933, 'learning_rate': 8.16326530612245e-07, 'epoch': 1.0}\n",
      "{'loss': 0.582, 'grad_norm': 1.4490996599197388, 'learning_rate': 4.081632653061225e-07, 'epoch': 1.0}\n",
      "{'loss': 0.4464, 'grad_norm': 1.344383955001831, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd182d50eb024fabbc427425c69dfb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6263864636421204, 'eval_runtime': 313.2449, 'eval_samples_per_second': 0.638, 'eval_steps_per_second': 0.638, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\peft\\utils\\save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Fine Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset.shuffle(seed=65).select(range(1200, 1205))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flags': 'BELMQZ',\n",
       " 'instruction': 'i do not know how to inform of a trouble withpayments',\n",
       " 'category': 'PAYMENT',\n",
       " 'intent': 'payment_issue',\n",
       " 'response': \"Don't worry, I'm here to guide you through the process of reporting any trouble you're experiencing with your payments. To inform us about the issue, you can reach out to our customer support team via phone or chat. They are available {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. Our dedicated team will assist you step-by-step in notifying us about the trouble, ensuring that it gets resolved as quickly as possible. We appreciate you bringing this to our attention, and we want to assure you that we're committed to providing you with the best assistance for your payment concerns.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting The Lora Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"C:/Users/User/Data Science/Deep Learning/Generative AI/Fine Tuning LLMs/fine-tuning llama 3.2 1B/llama-3.2-3b-it-Ecommerce-ChatBot/checkpoint-500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel(model=model, peft_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "    Be polite to customers and answer all their questions.\n",
    "    If the question is out of context and is not related to an e-commerce business, let them know you can not help and that they should look elsewhere for answers.\n",
    "    \"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": \"I have to see what payment payment modalities are accepted\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n    Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nI have to see what payment payment modalities are accepted<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_eval_template(row):\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model, trust_remote_code=True)\n",
    "\n",
    "    instruction = \"\"\"You are a top-rated customer service agent named John. \n",
    "        Be polite to customers and answer all their questions.\n",
    "        If the question is out of context and is not related to an e-commerce business, let them know you can not help and that they should look elsewhere for answers.\n",
    "        \"\"\"\n",
    "\n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction},\n",
    "                {\"role\": \"user\", \"content\": row[\"instruction\"]}]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(row_json, tokenize=False, add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt_1 = format_eval_template(eval_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not know how to inform of a trouble withpayments'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are a top-rated customer service agent named John. \\n        Be polite to customers and answer all their questions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\ni do not know how to inform of a trouble withpayments<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_prompt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eval_data_and_pred(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', truncation=True).to(\"cuda\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    outputs = lora_model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flags': 'BELMQZ',\n",
       " 'instruction': 'i do not know how to inform of a trouble withpayments',\n",
       " 'category': 'PAYMENT',\n",
       " 'intent': 'payment_issue',\n",
       " 'response': \"Don't worry, I'm here to guide you through the process of reporting any trouble you're experiencing with your payments. To inform us about the issue, you can reach out to our customer support team via phone or chat. They are available {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. Our dedicated team will assist you step-by-step in notifying us about the trouble, ensuring that it gets resolved as quickly as possible. We appreciate you bringing this to our attention, and we want to assure you that we're committed to providing you with the best assistance for your payment concerns.\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = preprocess_eval_data_and_pred(eval_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'm here to help. Don't worry, it's completely normal to have questions or concerns about your payments. Can you please tell me more about what's not working as expected with your payments? What kind of issue are you experiencing? Is it a payment that's been delayed, missed, or something else?\n"
     ]
    }
   ],
   "source": [
    "print(text.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_1 = [{\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": \"what is your name and what do you do\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = tokenizer.apply_chat_template(message_1, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt_2 = preprocess_eval_data_and_pred(prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "My name is John, and I'm a dedicated customer service representative. I'm here to help you with any questions or concerns you may have. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(eval_prompt_2.split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_2 = [{\"role\": \"system\", \"content\": instruction},\n",
    "             {\"role\": \"user\", \"content\": \"what do you know about wind and air\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = tokenizer.apply_chat_template(\n",
    "    message_2, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = preprocess_eval_data_and_pred(prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I'd be happy to help you with any questions you have about wind and air.\n",
      "\n",
      "Wind and air are fascinating topics that have been studied extensively in various fields, including physics, meteorology, and engineering.\n",
      "\n",
      "**What is wind?**\n",
      "\n",
      "Wind is the movement of air in the atmosphere, which is created by the uneven heating of the Earth's surface by the sun. The air rises in areas of high temperature and sinks in areas of low temperature. This movement of air is known as convection.\n",
      "\n",
      "**Types of wind:**\n",
      "\n",
      "There are several types of wind, including:\n",
      "\n",
      "1. **Trade winds**: These are winds that blow from the equator towards the poles.\n",
      "2. **Westerlies**: These are winds that blow from the west towards the\n"
     ]
    }
   ],
   "source": [
    "print(response.split(\"assistant\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
